#梯度下降法（Gradient Descent）介绍
===

*1.梯度下降法  
**是一种基于搜索的最优化方法**  
**作用**：最小化一个损失函数  
**梯度上升法**：最大化一个效用函数

给定目标函数分f(x)和初始点x0  



导数和偏导的区别：导数和偏导，偏导是因为有很多未知数，每次只能对其中一个求导，所以叫偏导



**低维空间：**
![](https://ws2.sinaimg.cn/large/0069RVTdly1fuxbhpdhxmj30vf0hwgoi.jpg)


**高维空间：**
![](https://ws1.sinaimg.cn/large/0069RVTdly1fuxbialzmaj30xa0ibdjm.jpg)
梯度代表方向，代表J增大最快的方向






*2.考虑冲量的梯度下降法  







