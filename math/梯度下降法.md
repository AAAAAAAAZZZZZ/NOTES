#梯度下降法（Gradient Descent）介绍
===

*1.梯度下降法  
**是一种基于搜索的最优化方法**  
**作用**：最小化一个损失函数  
**梯度上升法**：最大化一个效用函数

给定目标函数分f(x)和初始点x0  



导数和偏导的区别：导数和偏导，偏导是因为有很多未知数，每次只能对其中一个求导，所以叫偏导



**低维空间：**
![image](http://note.youdao.com/yws/res/2836/WEBRESOURCE9a4a1929012faab81a640233feb74a81)


**高维空间：**
![image](http://note.youdao.com/yws/res/2826/WEBRESOURCEd2450d38082114e48bb61a7cc4e80f10)
梯度代表方向，代表J增大最快的方向





*2.考虑冲量的梯度下降法  







